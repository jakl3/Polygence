{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60012cdc-bf72-44cb-86c3-7e16b8ef0fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df90652e-9e56-41c4-b5be-e53e971f02bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = monai.networks.nets.DenseNet121(spatial_dims=3, in_channels=1, out_channels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6442c3f5-9193-452c-8632-2e8c80575c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d5ddddd-abdc-4da4-a9cf-20aa5c40582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_scheduler(optimizer, epoch, initial_lr=1e-2, lr_decay=0.1, last_step=70):\n",
    "    \"\"\"Decay learning rate by lr_decay on predefined epochs\"\"\"\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = initial_lr * lr_decay ** (epoch/last_step)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fab322c-bba7-4708-b231-2877ce61b6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 current lr: 0.01\n",
      "1 current lr: 0.009676410537094535\n",
      "2 current lr: 0.009363292088239415\n",
      "3 current lr: 0.009060305822453377\n",
      "4 current lr: 0.008767123872968682\n",
      "5 current lr: 0.00848342898244072\n",
      "6 current lr: 0.008208914159638257\n",
      "7 current lr: 0.007943282347242816\n",
      "8 current lr: 0.0076862461003977395\n",
      "9 current lr: 0.007437527275659046\n",
      "10 current lr: 0.007196856730011521\n",
      "11 current lr: 0.006963974029624319\n",
      "12 current lr: 0.0067386271680309456\n",
      "13 current lr: 0.006520572293428615\n",
      "14 current lr: 0.006309573444801933\n",
      "15 current lr: 0.006105402296585329\n",
      "16 current lr: 0.005907837911587944\n",
      "17 current lr: 0.005716666501913616\n",
      "18 current lr: 0.005531681197617227\n",
      "19 current lr: 0.005352681822847105\n",
      "20 current lr: 0.005179474679231212\n",
      "21 current lr: 0.005011872336272724\n",
      "22 current lr: 0.004849693428528199\n",
      "23 current lr: 0.004692762459348838\n",
      "24 current lr: 0.004540909610972476\n",
      "25 current lr: 0.004393970560760791\n",
      "26 current lr: 0.0042517863033828904\n",
      "27 current lr: 0.004114202978752843\n",
      "28 current lr: 0.0039810717055349725\n",
      "29 current lr: 0.003852248420036752\n",
      "30 current lr: 0.003727593720314941\n",
      "31 current lr: 0.003606972715326291\n",
      "32 current lr: 0.0034902548789595804\n",
      "33 current lr: 0.0033773139087910097\n",
      "34 current lr: 0.003268027589410126\n",
      "35 current lr: 0.0031622776601683794\n",
      "36 current lr: 0.0030599496872071963\n",
      "37 current lr: 0.0029609329396270835\n",
      "38 current lr: 0.0028651202696637814\n",
      "39 current lr: 0.0027724079967417744\n",
      "40 current lr: 0.002682695795279726\n",
      "41 current lr: 0.0025958865861263943\n",
      "42 current lr: 0.0025118864315095803\n",
      "43 current lr: 0.002430604433384409\n",
      "44 current lr: 0.002351952635070959\n",
      "45 current lr: 0.0022758459260747883\n",
      "46 current lr: 0.0022022019499873756\n",
      "47 current lr: 0.0021309410153667976\n",
      "48 current lr: 0.0020619860095022202\n",
      "49 current lr: 0.0019952623149688802\n",
      "50 current lr: 0.0019306977288832503\n",
      "51 current lr: 0.0018682223847710372\n",
      "52 current lr: 0.0018077686769634345\n",
      "53 current lr: 0.0017492711874398427\n",
      "54 current lr: 0.0016926666150378759\n",
      "55 current lr: 0.0016378937069540642\n",
      "56 current lr: 0.0015848931924611134\n",
      "57 current lr: 0.0015336077187700118\n",
      "58 current lr: 0.0014839817889675652\n",
      "59 current lr: 0.0014359617019622148\n",
      "60 current lr: 0.0013894954943731378\n",
      "61 current lr: 0.0013445328842997609\n",
      "62 current lr: 0.0013010252169108317\n",
      "63 current lr: 0.0012589254117941673\n",
      "64 current lr: 0.0012181879120101158\n",
      "65 current lr: 0.0011787686347935874\n",
      "66 current lr: 0.001140624923851321\n",
      "67 current lr: 0.0011037155032027571\n",
      "68 current lr: 0.0010680004325145757\n",
      "69 current lr: 0.0010334410638805562\n",
      "70 current lr: 0.001\n",
      "71 current lr: 0.0009676410537094536\n",
      "72 current lr: 0.0009363292088239418\n",
      "73 current lr: 0.0009060305822453375\n",
      "74 current lr: 0.0008767123872968683\n",
      "75 current lr: 0.0008483428982440722\n",
      "76 current lr: 0.0008208914159638259\n",
      "77 current lr: 0.0007943282347242814\n",
      "78 current lr: 0.0007686246100397738\n",
      "79 current lr: 0.0007437527275659046\n",
      "80 current lr: 0.0007196856730011523\n",
      "81 current lr: 0.0006963974029624317\n",
      "82 current lr: 0.0006738627168030944\n",
      "83 current lr: 0.0006520572293428616\n",
      "84 current lr: 0.0006309573444801933\n",
      "85 current lr: 0.000610540229658533\n",
      "86 current lr: 0.0005907837911587944\n",
      "87 current lr: 0.0005716666501913616\n",
      "88 current lr: 0.0005531681197617227\n",
      "89 current lr: 0.0005352681822847106\n",
      "90 current lr: 0.000517947467923121\n",
      "91 current lr: 0.0005011872336272723\n",
      "92 current lr: 0.00048496934285281984\n",
      "93 current lr: 0.00046927624593488387\n",
      "94 current lr: 0.0004540909610972477\n",
      "95 current lr: 0.0004393970560760791\n",
      "96 current lr: 0.00042517863033828907\n",
      "97 current lr: 0.0004114202978752843\n",
      "98 current lr: 0.00039810717055349735\n",
      "99 current lr: 0.00038522484200367515\n",
      "100 current lr: 0.000372759372031494\n",
      "101 current lr: 0.0003606972715326291\n",
      "102 current lr: 0.0003490254878959581\n",
      "103 current lr: 0.0003377313908791009\n",
      "104 current lr: 0.0003268027589410125\n",
      "105 current lr: 0.000316227766016838\n",
      "106 current lr: 0.00030599496872071966\n",
      "107 current lr: 0.0002960932939627085\n",
      "108 current lr: 0.0002865120269663781\n",
      "109 current lr: 0.00027724079967417746\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(110):\n",
    "    lr_scheduler(optimizer, epoch, lr_decay=0.1)\n",
    "    curr_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f'{epoch} current lr: {curr_lr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d30860-75d9-453c-a83f-92e2c218c8cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (Polygence)",
   "language": "python",
   "name": "polygence"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
